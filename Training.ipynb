{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**: Physics-based Learned Design\n",
    "\n",
    "\n",
    "**Purpose:** Train a physics-based network to learn the experiment design (LED patterns) for Fourier Ptychographic Microscopy.\n",
    "\n",
    "**Monitor Training:** If you have enabled tensorboards (```tensorboard=True```), start the tensorboard (```tensorboard --logdir runs```) and the training can be monitored during training at the specified link.\n",
    "\n",
    "**Parameters:**\n",
    "* path (string) - _training dataset path_\n",
    "* training_iter (int) - _number of iterations for training_\n",
    "* step_size (float) - _step size for training_\n",
    "* batch_size (int) - _batch size per training iteration_\n",
    "* num_batch (int) - _number of batches_\n",
    "* loss (string) - _loss function for training (mse on the complex value, mse on the amplitude, mse on the phase)_\n",
    "* test_freq (int) - _test dataset evaluated every number of training iterations_\n",
    "* optim (string) - _optimizer for training (_e.g._ adam, sgd)_\n",
    "* gpu (int) - _GPU device number used for training (-1 for cpu)_\n",
    "* verbose (bool) - _prints extra outputs_\n",
    "* tensorboard (bool) - _writes out intermediate training information to a tensorboard_\n",
    "* alpha (float) - _step size for physics-based network_\n",
    "* num_meas (int) - _number of measurements for the learned design_\n",
    "* num_bf (int) - _number of bright-field images for learned design constraint_\n",
    "* num_df (int) - _number of dark-field images for learned design constraint_\n",
    "* num_unrolls (int) - _number of layers for physics-based network_\n",
    "\n",
    "**Author:** Michael Kellman (kellman dot berkeley dot edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "sys.path.append('./source/')\n",
    "import dataloader\n",
    "import visualizer\n",
    "import model\n",
    "from recon import evaluate, makeNetwork\n",
    "from utility import getPhase, getAbs\n",
    "\n",
    "def get_time_stamp():\n",
    "    return str(datetime.now())[11:19] + '_'\n",
    "\n",
    "def format_loss_monitor(batch, loss, time):\n",
    "    return 'batch={0:3d} | loss={1:.5f} | log loss={2:2.3f} | time={3:2.3f}'.format(batch, loss, np.log10(loss), time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning arguments\n",
    "num_batches = 10\n",
    "batch_size = 5\n",
    "path = './data/training_data_amplitude.mat' \n",
    "training_iter = 100\n",
    "step_size = 0.001\n",
    "loss = 'abs' # other options include mse on only the abs or the phase)\n",
    "test_freq = 1\n",
    "optim = 'adam' # other options include sgd\n",
    "gpu = 0 # if -1 then 'cpu'\n",
    "verbose = False\n",
    "tensorboard = False\n",
    "\n",
    "# reconstruction arguments\n",
    "alpha = 1e-1\n",
    "num_meas = 6\n",
    "num_bf = 1\n",
    "num_df = 5\n",
    "num_unrolls = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "if gpu < 0:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    torch.cuda.set_device(gpu)\n",
    "    device = torch.device(\"cuda:\"+str(gpu) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = dataloader.dataloader(path, num_batches, batch_size, device)\n",
    "metadata = dataset.getMetadata()\n",
    "metadata['Np'] = dataset[0][0].shape[2:]\n",
    "metadata['num_bf'] = num_bf\n",
    "metadata['num_df'] = num_df\n",
    "metadata['num_unrolls'] = num_unrolls\n",
    "metadata['alpha'] = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction's pixel size (um): 0.414516129032258\n",
      "System's pixel size limit (um): 1.285\n",
      "Camera's effective pixel size (um): 1.625\n"
     ]
    }
   ],
   "source": [
    "# Define network/reconstruction\n",
    "network = model.model(metadata, device=device)\n",
    "\n",
    "# Setup optimizer\n",
    "tvars = network.network.parameters()\n",
    "if optim == 'adam':\n",
    "    optimizer = torch.optim.Adam(tvars, lr=step_size)\n",
    "elif optim == 'sgd':\n",
    "    optimizer = torch.optim.SGD(tvars, lr=step_size)\n",
    "else:\n",
    "    assert False, 'Not valid optimizer (sgd, adam)'\n",
    "\n",
    "# Setup loss function\n",
    "if loss == \"mse\":\n",
    "    loss_func = lambda x1, x2: torch.mean((x1-x2)**2)\n",
    "elif loss == \"abs\":\n",
    "    loss_func = lambda x1, x2: torch.mean((getAbs(x1)-getAbs(x2))**2)\n",
    "elif loss == \"phase\":\n",
    "    loss_func = lambda x1, x2: torch.mean((getPhase(x1)-getPhase(x2))**2)\n",
    "else:\n",
    "    assert False, 'Not valid loss function (try mse)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tensorboard writer\n",
    "exp_string = 'batch_size={0:d}_stepsize={1:.3f}_loss_fn={8:}_optim={2:}_num_unrolls={3:d}_alpha={4:.3f}_num_df={5:d}_num_bf={6:d}_num_leds={7:d}'.format(batch_size, step_size, optim, num_unrolls, alpha, num_df, num_bf, metadata['Nleds'], loss)\n",
    "exp_time = get_time_stamp()\n",
    "exp_dir = './runs/' + exp_time + exp_string\n",
    "if verbose: print(exp_dir)\n",
    "if tensorboard: \n",
    "    writer = SummaryWriter(exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Physics-based learned Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.91 GiB total capacity; 3.65 GiB already allocated; 3.06 MiB free; 732.36 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-86c1f4bf90d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mxN_tmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestFlag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxN_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/PYTHON/LearnedDesignFPM/source/recon.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(network, x0, interFlag, testFlag, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minterFlag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mXall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/PYTHON/LearnedDesignFPM/source/fpm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, device)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_est\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/PYTHON/LearnedDesignFPM/source/fpm.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x, device)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/PYTHON/LearnedDesignFPM/source/fpm.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, field_est, device)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmul_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAjx_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmeas_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmul_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplanewaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmul_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpupils\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 11.91 GiB total capacity; 3.65 GiB already allocated; 3.06 MiB free; 732.36 MiB cached)"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for ii in range(training_iter):\n",
    "    batch_index = np.mod(ii,num_batches-1)\n",
    "    input_data, output_data = dataset[batch_index]        \n",
    "\n",
    "    # forward evaluation (loop over batches)\n",
    "    loss_training = 0.\n",
    "    network.network.zero_grad()\n",
    "    for bb in range(batch_size):\n",
    "        zgFlag = bb == 0\n",
    "        start_time = time.time()\n",
    "        x0 = network.initialize(input_data[bb:bb+1,...].to(device), device=device)\n",
    "        xN_tmp, _ = evaluate(network.network, x0, testFlag = False, device = device)\n",
    "        loss_tmp = loss_func(output_data[bb:bb+1,...].to(device),xN_tmp)\n",
    "        loss_tmp.backward()\n",
    "        end_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            loss_training += loss_tmp\n",
    "\n",
    "    # gradient and projection updates\n",
    "    optimizer.step()\n",
    "    network.projection()\n",
    "\n",
    "\n",
    "    # testing evaluation\n",
    "    if np.mod(ii, test_freq) == 0:\n",
    "        input_data, output_data = dataset[num_batches-1]            \n",
    "\n",
    "        # forward evaluation (loop over batches)\n",
    "        loss_testing = 0.\n",
    "        for bb in range(batch_size):\n",
    "            x0 = network.initialize(input_data[bb:bb+1,...].to(device), device = device)\n",
    "            xN_test, _ = evaluate(network.network, x0, testFlag = True, device = device)\n",
    "            loss_tmp = loss_func(output_data[bb:bb+1,...].to(device),xN_test)\n",
    "            with torch.no_grad():\n",
    "                loss_testing += loss_tmp.cpu().numpy()\n",
    "\n",
    "\n",
    "        # tensorboard writer\n",
    "        if tensorboard:\n",
    "            # visualizing\n",
    "            with torch.no_grad():\n",
    "                fig = visualizer.visualize(network.grad.C.data.cpu().numpy(), metadata)\n",
    "            os.system('mkdir -p ' + exp_dir + '/tmp/')\n",
    "            img_file_path = exp_dir + '/tmp/leds_{0:4d}.png'.format(ii)\n",
    "            fig.savefig(img_file_path, transparent=True, dpi=150)\n",
    "            plt.close()\n",
    "            led_img = mpimg.imread(img_file_path)[...,:3]\n",
    "\n",
    "\n",
    "            # writing to tensorboard\n",
    "            writer.add_scalar('Loss/test', loss_testing/batch_size, ii)\n",
    "            writer.add_scalar('Loss/train', loss_training/batch_size, ii)\n",
    "            writer.add_image('Visual/leds', led_img, ii, dataformats='HWC')\n",
    "\n",
    "\n",
    "            # saving checkpoints\n",
    "            saveDict = {'model_state_dict':network.network.state_dict(),\n",
    "                        'loss_testing':loss_testing,\n",
    "                        'loss_training':loss_training,\n",
    "                        'alpha':alpha,\n",
    "                        'num_unrolls':num_unrolls,\n",
    "                        'num_meas':num_meas,\n",
    "                        'num_bf':num_bf,\n",
    "                        'num_df':num_df,\n",
    "                       }             \n",
    "            torch.save(saveDict, exp_dir + '/ckpt.tar')\n",
    "\n",
    "    # progress print statement\n",
    "    print(format_loss_monitor(ii, loss_testing / batch_size, end_time - start_time), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
